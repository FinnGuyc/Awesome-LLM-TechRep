# Awesome-LLM-TechRep
A curated collection of technical reports related to TOP large language models.

## Qwen
Qwen: https://arxiv.org/abs/2309.16609
Qwen-VL: https://arxiv.org/abs/2308.12966
Qwen2: https://arxiv.org/abs/2407.10671
Qwen2-Audio: https://export.arxiv.org/abs/2407.10759
Qwen2.5-Coder: https://arxiv.org/abs/2409.12186

## Deepseek
Deepseek: https://arxiv.org/abs/2401.02954
Deepseek-v2: https://arxiv.org/abs/2405.04434

## MiniCPM
MiniCPM: https://arxiv.org/abs/2404.06395
MiniCPM-v: https://arxiv.org/abs/2408.01800

## Baichuan
Baichuan-Omin: https://arxiv.org/abs/2410.08565
Baichuan2: https://arxiv.org/abs/2309.10305
Baichuan2-Sum: https://arxiv.org/abs/2401.15496

## ChatGPT
GPT: https://arxiv.org/abs/2305.10435
GPT-2: https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf
GPT-3: https://arxiv.org/abs/2005.14165
GPT-4: https://arxiv.org/abs/2303.08774
GPT-4o: https://openai.com/index/hello-gpt-4o/
GPT-o1: https://openai.com/index/learning-to-reason-with-llms/

## LLaMA
LLaMA: https://arxiv.org/abs/2302.13971
LLaMA-2: https://arxiv.org/abs/2307.09288
LLaMA-3: https://arxiv.org/abs/2407.21783
LLaMA-3.1: https://ai.meta.com/blog/meta-llama-3-1/
LLaMA-3.2: https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/



